import os
import json
import argparse
import arxiv
import google.generativeai as genai
import openai
from datetime import datetime, timedelta, timezone

# --- è¯­è¨€å’Œæ¨¡æ¿é…ç½® (Language & Template Configuration) ---

PROMPTS = {
    "en": {
        "system_message": "You are a helpful research assistant providing JSON output.",
        "template": """
You are a senior AI researcher specializing in Large Language Models.
Based on the title and abstract of the following paper, please perform these tasks:

**Paper Title:** {title}
**Paper Abstract:** {abstract}

**Tasks:**
1.  **Categorize** the paper into ONE of the following categories: 
    [Model Architecture, Training & Optimization, Data & Pre-training, Fine-tuning & Adaptation, Evaluation & Benchmarking, Multimodality, Applications, Safety & Ethics, Theory & Analysis, Other].
2.  **Summarize the main contribution** in a single, concise sentence.
3.  **Rate its potential novelty** on a scale of 1 to 5 (1=Incremental, 3=Interesting, 5=Potential Breakthrough).

Provide your response in a valid JSON format, like this:
{{"category": "...", "contribution": "...", "novelty": ...}}
"""
    },
    "zh": {
        "system_message": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ç ”ç©¶åŠ©ç†ï¼Œéœ€æä¾› JSON æ ¼å¼çš„è¾“å‡ºã€‚",
        "template": """
ä½ æ˜¯ä¸€ä½ä¸“æ”»å¤§å‹è¯­è¨€æ¨¡å‹çš„é«˜çº§AIç ”ç©¶å‘˜ã€‚
æ ¹æ®ä»¥ä¸‹è®ºæ–‡çš„æ ‡é¢˜å’Œæ‘˜è¦ï¼Œè¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

**è®ºæ–‡æ ‡é¢˜:** {title}
**è®ºæ–‡æ‘˜è¦:** {abstract}

**ä»»åŠ¡:**
1.  **åˆ†ç±»**: å°†è®ºæ–‡å½’å…¥ä»¥ä¸‹ç±»åˆ«ä¹‹ä¸€ï¼š
    [æ¨¡å‹æ¶æ„, è®­ç»ƒä¸ä¼˜åŒ–, æ•°æ®ä¸é¢„è®­ç»ƒ, å¾®è°ƒä¸é€‚é…, è¯„æµ‹ä¸åŸºå‡†, å¤šæ¨¡æ€, åº”ç”¨, å®‰å…¨ä¸ä¼¦ç†, ç†è®ºä¸åˆ†æ, å…¶ä»–]ã€‚
2.  **æ€»ç»“æ ¸å¿ƒè´¡çŒ®**: ç”¨ä¸€ä¸ªç®€æ´çš„å¥å­æ€»ç»“è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ã€‚
3.  **è¯„å®šæ–°é¢–æ€§**: åœ¨1åˆ°5çš„èŒƒå›´å†…è¯„ä»·å…¶æ½œåœ¨æ–°é¢–æ€§ (1=å¾®åˆ›æ–°, 3=æœ‰è¶£, 5=æ½œåœ¨çªç ´)ã€‚

è¯·ä»¥æœ‰æ•ˆçš„JSONæ ¼å¼æä¾›æ‚¨çš„å›ç­”ï¼Œä¾‹å¦‚ï¼š
{{"category": "...", "contribution": "...", "novelty": ...}}
"""
    }
}

REPORT_TEMPLATES = {
    "en": {
        "title": "# Daily arXiv LLM Digest - {report_date}",
        "summary_by": "Your daily summary of new papers on LLMs, analyzed by **{provider}**.",
        "top_recommendation": "## ğŸ”¥ Today's Top Recommendation",
        "authors": "- **Authors**: {authors}",
        "category": "- **Category**: `{category}`",
        "novelty_score": "- **Novelty Score**: `{novelty}/5`",
        "contribution": "- **Contribution**: {contribution}",
        "abstract": "**Abstract**: *{abstract}*",
        "other_papers": "---\n\n## ğŸ“š Other Papers Today",
        "other_paper_category": "- **Category**: `{category}` | **Novelty**: `{novelty}/5`",
        "no_papers_found": "# Daily arXiv LLM Digest\n\nNo new papers found today."
    },
    "zh": {
        "title": "# arXiv LLM æ¯æ—¥æ‘˜è¦ - {report_date}",
        "summary_by": "æ‚¨çš„ LLM è®ºæ–‡æ¯æ—¥æ‘˜è¦ï¼Œç”± **{provider}** åˆ†æã€‚",
        "top_recommendation": "## ğŸ”¥ ä»Šæ—¥æœ€ä½³æ¨è",
        "authors": "- **ä½œè€…**: {authors}",
        "category": "- **ç±»åˆ«**: `{category}`",
        "novelty_score": "- **æ–°é¢–æ€§è¯„åˆ†**: `{novelty}/5`",
        "contribution": "- **æ ¸å¿ƒè´¡çŒ®**: {contribution}",
        "abstract": "**æ‘˜è¦**: *{abstract}*",
        "other_papers": "---\n\n## ğŸ“š ä»Šæ—¥å…¶ä»–è®ºæ–‡",
        "other_paper_category": "- **ç±»åˆ«**: `{category}` | **æ–°é¢–æ€§**: `{novelty}/5`",
        "no_papers_found": "# arXiv LLM æ¯æ—¥æ‘˜è¦\n\nä»Šæ—¥æœªå‘ç°æ–°è®ºæ–‡.",
        "translation_template": "Translate the following English abstract into concise, academic Chinese:\n\n---\n\n{text}"
    }
}


# --- æ ¸å¿ƒåŠŸèƒ½ (Core Functions) ---

def fetch_recent_papers(search_query, max_results, days):
    """ä» Arxiv è·å–è¿‡å»æŒ‡å®šå¤©æ•°çš„è®ºæ–‡"""
    print(f"Fetching recent papers from the last {days} day(s) from arXiv...")
    start_date_utc = datetime.now(timezone.utc) - timedelta(days=days)
    
    search = arxiv.Search(
        query=search_query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.SubmittedDate
    )
    
    recent_papers = []
    for result in search.results():
        if result.published > start_date_utc:
            recent_papers.append(result)
            
    print(f"Found {len(recent_papers)} new papers from the last {days} day(s).")
    return recent_papers

def _analyze_with_google(model, paper, lang):
    """ä½¿ç”¨ Google Gemini åˆ†æè®ºæ–‡"""
    prompt = PROMPTS[lang]["template"].format(title=paper.title, abstract=paper.summary)
    response = model.generate_content(prompt)
    cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
    return json.loads(cleaned_response)

def _analyze_with_openai_compatible(client, model_name, paper, lang):
    """ä½¿ç”¨ OpenAI å…¼å®¹çš„ API (OpenAI, DeepSeek) åˆ†æè®ºæ–‡"""
    prompt = PROMPTS[lang]["template"].format(title=paper.title, abstract=paper.summary)
    system_message = PROMPTS[lang]["system_message"]
    response = client.chat.completions.create(
        model=model_name,
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )
    return json.loads(response.choices[0].message.content)

def analyze_paper(provider, client, model_name, paper, lang):
    """æ ¹æ®æä¾›å•†é€‰æ‹©åˆ†æå‡½æ•°"""
    print(f"  Analyzing with {provider}: {paper.title[:60]}...")
    try:
        if provider == 'google':
            return _analyze_with_google(client, paper, lang)
        elif provider in ['openai', 'deepseek']:
            return _analyze_with_openai_compatible(client, model_name, paper, lang)
    except Exception as e:
        print(f"    [!] Error analyzing paper: {e}")
        return None

def _translate_text(text, provider, client, model_name):
    """ä½¿ç”¨ LLM å°†æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡"""
    print("  Translating top recommendation's abstract to Chinese...")
    prompt = REPORT_TEMPLATES["zh"]["translation_template"].format(text=text)
    try:
        if provider == 'google':
            response = client.generate_content(prompt)
            return response.text
        elif provider in ['openai', 'deepseek']:
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful translation assistant, translating English to Chinese."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
    except Exception as e:
        print(f"    [!] Error translating text: {e}")
        return None

def generate_markdown_report(analyzed_papers, provider, lang, client, model_name):
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
    template = REPORT_TEMPLATES[lang]
    if not analyzed_papers:
        return template["no_papers_found"]

    analyzed_papers.sort(key=lambda x: x['analysis'].get('novelty', 0), reverse=True)
    
    recommendation = analyzed_papers[0]
    other_papers = analyzed_papers[1:]
    
    report_date = datetime.now().strftime("%Y-%m-%d")
    md_content = template["title"].format(report_date=report_date) + "\n\n"
    md_content += template["summary_by"].format(provider=provider) + "\n\n"
    
    md_content += template["top_recommendation"] + "\n\n"
    p = recommendation['paper']
    a = recommendation['analysis']
    md_content += f"### [{p.title}]({p.entry_id})\n"
    md_content += template["authors"].format(authors=', '.join(author.name for author in p.authors)) + "\n"
    md_content += template["category"].format(category=a.get('category', 'N/A')) + "\n"
    md_content += template["novelty_score"].format(novelty=a.get('novelty', 'N/A')) + "\n"
    md_content += template["contribution"].format(contribution=a.get('contribution', 'N/A')) + "\n\n"
    
    # å¦‚æœæ˜¯ä¸­æ–‡æŠ¥å‘Šï¼Œç¿»è¯‘æœ€ä½³æ¨èçš„æ‘˜è¦
    abstract_to_display = p.summary.replace('\n', ' ')
    if lang == 'zh':
        translated_abstract = _translate_text(p.summary, provider, client, model_name)
        if translated_abstract:
            abstract_to_display = translated_abstract.replace('\n', ' ')

    md_content += template["abstract"].format(abstract=abstract_to_display) + "\n\n"
    
    if other_papers:
        md_content += template["other_papers"] + "\n\n"
        for item in other_papers:
            p = item['paper']
            a = item['analysis']
            md_content += f"### [{p.title}]({p.entry_id})\n"
            md_content += template["other_paper_category"].format(category=a.get('category', 'N/A'), novelty=a.get('novelty', 'N/A')) + "\n"
            md_content += template["contribution"].format(contribution=a.get('contribution', 'N/A')) + "\n\n"
            
    return md_content

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    parser = argparse.ArgumentParser(description="Fetch and analyze recent LLM papers from arXiv.")
    parser.add_argument("--provider", type=str, default="deepseek", choices=["google", "openai", "deepseek"], help="The LLM provider to use.")
    parser.add_argument("--max-results", type=int, default=20, help="Maximum number of papers to process.")
    parser.add_argument("-d", "--days", type=int, default=2, help="Number of days back to search for papers.")
    parser.add_argument("--lang", type=str, default="zh", choices=["en", "zh"], help="Language for the output report (en/zh).")
    
    # API Keys - prioritize command-line args, then fall back to environment variables
    parser.add_argument("--google-api-key", type=str, default=os.getenv("GOOGLE_API_KEY"), help="Google API Key.")
    parser.add_argument("--openai-api-key", type=str, default=os.getenv("OPENAI_API_KEY"), help="OpenAI API Key.")
    parser.add_argument("--deepseek-api-key", type=str, default=os.getenv("DEEPSEEK_API_KEY"), help="DeepSeek API Key.")

    args = parser.parse_args()

    # --- é…ç½® (Configuration) ---
    # Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
    SEARCH_QUERY = 'cat:cs.CL OR cat:cs.AI OR cat:cs.LG'
    OUTPUT_DIR = "arxiv_digests_md"
    MODEL_CONFIG = {
        "google": "gemini-2.5-flash",
        "openai": "gpt-5",
        "deepseek": "deepseek-chat"
    }

    client = None
    model_name = MODEL_CONFIG[args.provider]

    print(f"Using LLM provider: {args.provider}")
    if args.provider == 'google':
        if not args.google_api_key:
            raise ValueError("Google API Key not provided. Set GOOGLE_API_KEY environment variable or use --google-api-key.")
        genai.configure(api_key=args.google_api_key)
        client = genai.GenerativeModel(model_name)
    
    elif args.provider == 'openai':
        if not args.openai_api_key:
            raise ValueError("OpenAI API Key not provided. Set OPENAI_API_KEY environment variable or use --openai-api-key.")
        client = openai.OpenAI(api_key=args.openai_api_key)

    elif args.provider == 'deepseek':
        if not args.deepseek_api_key:
            raise ValueError("DeepSeek API Key not provided. Set DEEPSEEK_API_KEY environment variable or use --deepseek-api-key.")
        client = openai.OpenAI(api_key=args.deepseek_api_key, base_url="https://api.deepseek.com/v1")

    else:
        raise ValueError(f"Unsupported LLM provider: {args.provider}")

    papers = fetch_recent_papers(SEARCH_QUERY, args.max_results, args.days)
    if not papers:
        print("No new papers to process. Exiting.")
        return

    analyzed_papers = []
    for paper in papers:
        analysis = analyze_paper(args.provider, client, model_name, paper, args.lang)
        if analysis:
            analyzed_papers.append({"paper": paper, "analysis": analysis})
    
    report = generate_markdown_report(analyzed_papers, args.provider, args.lang, client, model_name)

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    report_date = datetime.now().strftime("%Y-%m-%d")
    output_filename = os.path.join(OUTPUT_DIR, f"digest_{report_date}.md")

    with open(output_filename, "w", encoding="utf-8") as f:
        f.write(report)
        
    print(f"\nâœ… Digest report generated successfully: {output_filename}")
    
    if analyzed_papers:
        print("\n--- Today's Recommendation ---")
        recommendation_part = report.split("---")[0]
        print(recommendation_part)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"An error occurred: {e}")
