# Daily arXiv LLM Digest - 2025-08-08

Your daily summary of new papers on LLMs, analyzed by **google**.

## ðŸ”¥ Today's Top Recommendation

### [The Missing Reward: Active Inference in the Era of Experience](http://arxiv.org/abs/2508.05619v1)
- **Authors**: Bo Wen
- **Category**: `Theory & Analysis`
- **Novelty Score**: `5/5`
- **Contribution**: The paper proposes Active Inference (AIF), integrated with Large Language Models, as a principled framework for autonomous AI agents to intrinsically formulate and pursue objectives by minimizing free energy, thereby overcoming reliance on external reward engineering and bridging the 'grounded-agency gap'.

**Abstract**: *This paper argues that Active Inference (AIF) provides a crucial foundation for developing autonomous AI agents capable of learning from experience without continuous human reward engineering. As AI systems begin to exhaust high-quality training data and rely on increasingly large human workforces for reward design, the current paradigm faces significant scalability challenges that could impede progress toward genuinely autonomous intelligence. The proposal for an ``Era of Experience,'' where agents learn from self-generated data, is a promising step forward. However, this vision still depends on extensive human engineering of reward functions, effectively shifting the bottleneck from data curation to reward curation. This highlights what we identify as the \textbf{grounded-agency gap}: the inability of contemporary AI systems to autonomously formulate, adapt, and pursue objectives in response to changing circumstances. We propose that AIF can bridge this gap by replacing external reward signals with an intrinsic drive to minimize free energy, allowing agents to naturally balance exploration and exploitation through a unified Bayesian objective. By integrating Large Language Models as generative world models with AIF's principled decision-making framework, we can create agents that learn efficiently from experience while remaining aligned with human values. This synthesis offers a compelling path toward AI systems that can develop autonomously while adhering to both computational and physical constraints.*

---

## ðŸ“š Other Papers Today

### [Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling](http://arxiv.org/abs/2508.05634v1)
- **Category**: `Safety & Ethics` | **Novelty**: `4/5`
- **Contribution**: The paper introduces a novel method that integrates adaptive conformal inference for pedestrian uncertainty estimation into constrained reinforcement learning, significantly enhancing the generalizable safety and robustness of crowd navigation robots in both in-distribution and out-of-distribution scenarios.

### [KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation](http://arxiv.org/abs/2508.05633v1)
- **Category**: `Data & Pre-training` | **Novelty**: `4/5`
- **Contribution**: The paper introduces KuaiLive, the first public, large-scale, real-time, and interactive dataset for live streaming recommendation, designed to bridge the research gap caused by the lack of realistic public data.

### [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](http://arxiv.org/abs/2508.05629v1)
- **Category**: `Fine-tuning & Adaptation` | **Novelty**: `4/5`
- **Contribution**: The paper introduces Dynamic Fine-Tuning (DFT), a simple, theoretically-grounded modification to Supervised Fine-Tuning (SFT) that dynamically rescales its objective function, leading to significantly improved LLM generalization by rectifying an implicit problematic reward structure.

### [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](http://arxiv.org/abs/2508.05628v1)
- **Category**: `Model Architecture` | **Novelty**: `4/5`
- **Contribution**: H-NET++ introduces a novel hierarchical dynamic-chunking model that learns linguistically-informed segmentation end-to-end, providing an effective tokenizer-free solution for morphologically-rich languages.

### [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](http://arxiv.org/abs/2508.05625v1)
- **Category**: `Theory & Analysis` | **Novelty**: `4/5`
- **Contribution**: This paper demonstrates that linear probes can effectively and efficiently uncover nuanced persuasion dynamics, including success, strategy, and timing, in multi-turn LLM conversations, offering advantages over prompting-based methods.

### [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](http://arxiv.org/abs/2508.05622v1)
- **Category**: `Evaluation & Benchmarking` | **Novelty**: `4/5`
- **Contribution**: This paper introduces LearnerAgent, a novel LLM-powered multi-agent framework that simulates human learning environments to explore dynamic learning processes and uncover the inherent learning profile of base LLMs.

### [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](http://arxiv.org/abs/2508.05616v1)
- **Category**: `Applications` | **Novelty**: `4/5`
- **Contribution**: TrajEvo introduces an LLM-driven evolutionary framework for automatically designing fast, explainable, and generalizable trajectory prediction heuristics, demonstrating superior performance, particularly in out-of-distribution scenarios.

### [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](http://arxiv.org/abs/2508.05615v1)
- **Category**: `Fine-tuning & Adaptation` | **Novelty**: `4/5`
- **Contribution**: The paper introduces GUI-RC and GUI-RCPO, novel test-time scaling and reinforcement learning methods that leverage spatial consistency across multiple model predictions to self-supervise and iteratively refine GUI grounding outputs on unlabeled data during inference.

### [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](http://arxiv.org/abs/2508.05614v1)
- **Category**: `Evaluation & Benchmarking` | **Novelty**: `4/5`
- **Contribution**: The paper introduces OmniEAR, a novel benchmark framework designed to rigorously evaluate large language models' embodied reasoning capabilities, specifically focusing on dynamic capability acquisition and autonomous multi-agent coordination.

### [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](http://arxiv.org/abs/2508.05606v1)
- **Category**: `Multimodality` | **Novelty**: `4/5`
- **Contribution**: Uni-CoT introduces a unified two-level Chain-of-Thought framework and a structured training paradigm to enable coherent, scalable, and grounded multimodal reasoning across text and vision within a single model, achieving SOTA performance.

### [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](http://arxiv.org/abs/2508.05600v1)
- **Category**: `Safety & Ethics` | **Novelty**: `4/5`
- **Contribution**: The paper formally proves the 'one-poison hypothesis' for linear regression and linear classification, demonstrating that a single, carefully chosen poison sample can effectively inject a backdoor with zero backdooring error and minimal impact on benign task performance, even for an adversary with limited knowledge.

### [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](http://arxiv.org/abs/2508.05592v1)
- **Category**: `Data & Pre-training` | **Novelty**: `4/5`
- **Contribution**: MathSmith proposes a novel reinforcement learning framework for synthesizing extremely challenging mathematical problems from scratch, addressing data scarcity to significantly enhance LLM reasoning capabilities.

### [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](http://arxiv.org/abs/2508.05581v1)
- **Category**: `Applications` | **Novelty**: `4/5`
- **Contribution**: This paper introduces an iterative 'synthesize, execute, debug, instruct' strategy that leverages Large Language Models to generate and refine interpretable computable phenotypes for clinical decision support, demonstrating their efficacy with high accuracy and data efficiency.

### [Learning to Reason for Factuality](http://arxiv.org/abs/2508.05618v1)
- **Category**: `Training & Optimization` | **Novelty**: `3/5`
- **Contribution**: This paper introduces a novel, multi-faceted reward function for online reinforcement learning to effectively reduce hallucination rates in reasoning LLMs while maintaining response detail and relevance.

### [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](http://arxiv.org/abs/2508.05613v1)
- **Category**: `Training & Optimization` | **Novelty**: `3/5`
- **Contribution**: The paper introduces Cooper, a novel reinforcement learning framework that co-optimizes policy and reward models to combat reward hacking and enhance robustness in LLM reasoning tasks.

### [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](http://arxiv.org/abs/2508.05612v1)
- **Category**: `Training & Optimization` | **Novelty**: `3/5`
- **Contribution**: Shuffle-R1 is an RL framework that improves the efficiency of MLLM fine-tuning by addressing training inefficiencies like advantage collapsing and rollout silencing through dynamic trajectory sampling and advantage-based batch reshuffling.

### [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](http://arxiv.org/abs/2508.05591v1)
- **Category**: `Applications` | **Novelty**: `3/5`
- **Contribution**: This study demonstrates that Kolmogorov-Arnold Networks (KANs) are an effective and interpretable alternative to conventional machine learning models for intrusion detection in IoT networks, achieving competitive performance.

### [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](http://arxiv.org/abs/2508.05587v1)
- **Category**: `Training & Optimization` | **Novelty**: `3/5`
- **Contribution**: The paper enhances the PyKEEN framework by integrating a modular suite of advanced negative sampling strategies, addressing a gap in existing KGE libraries and improving the training and performance of Knowledge Graph Embedding models.

