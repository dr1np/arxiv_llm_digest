# arXiv LLM 每日摘要 - 2025-08-09

您的 LLM 论文每日摘要，由 **deepseek** 分析。

## 🔥 今日最佳推荐

### [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](http://arxiv.org/abs/2508.05571v1)
- **作者**: Feiyu Wang, Guoan Wang, Yihao Zhang, Shengfan Wang, Weitao Li, Bokai Huang, Shimao Chen, Zihan Jiang, Rui Xu, Tong Yang
- **类别**: `训练与优化`
- **新颖性评分**: `5/5`
- **核心贡献**: 提出了Fairy±i，第一个将复数域LLM量化为2位（{±1, ±i}）的框架，通过利用复数域的表示优势提升全精度模型的准确性，并在保持严格存储和计算效率的同时超越了现有2位量化方法的性能上限。

**摘要**: *---  量化感知训练（QAT）将量化过程融入训练循环，使大语言模型（LLM）能够学习鲁棒的低比特表示，被广泛视为最具前景的研究方向之一。现有QAT研究均以最小化全精度模型的量化误差为目标，其全精度准确率构成性能上限（精度天花板），尚无方法尝试突破此限制。为打破这一限制，我们提出新范式：先抬升天花板（提升全精度模型性能），再将其高效量化为2比特。本文首次提出面向复数值LLM的2比特量化框架Fairy$\pm i$，其核心是通过复数域的表示优势提升全精度模型准确率——将权重映射至四次单位根$\{\pm1, \pm i\}$，形成完全对称且信息理论最优的2比特表示。关键的是，每个量化权值的实部或虚部必为零，使得推理过程仅需加法与元素交换即可完成（无需乘法运算）。实验表明，Fairy$\pm i$在PPL和下游任务上均超越现有2比特量化的精度天花板，同时严格保持存储与计算效率。该研究为极低比特约束下构建高精度实用化LLM开辟了新方向。    （注：根据学术规范，采用"全精度"对应"full-precision"；保留数学符号$\pm i$确保术语一致性；"PPL"作为通用指标名未翻译；通过"抬升天花板"的比喻保持原文突破性意象；补充括号说明使技术表述更清晰）*

---

## 📚 今日其他论文

### [Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling](http://arxiv.org/abs/2508.05634v1)
- **类别**: `安全与伦理` | **新颖性**: `4/5`
- **核心贡献**: 通过适应性符合推理和约束强化学习，提出了一种增强移动机器人在人群中导航安全性和鲁棒性的方法。

### [KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation](http://arxiv.org/abs/2508.05633v1)
- **类别**: `数据与预训练` | **新颖性**: `4/5`
- **核心贡献**: 介绍了KuaiLive，第一个来自中国领先直播平台快手、反映直播环境动态特性的实时互动数据集。

### [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](http://arxiv.org/abs/2508.05629v1)
- **类别**: `微调与适配` | **新颖性**: `4/5`
- **核心贡献**: 提出动态微调（DFT）方法，通过动态调整目标函数来改善大型语言模型的泛化能力。

### [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](http://arxiv.org/abs/2508.05628v1)
- **类别**: `模型架构` | **新颖性**: `4/5`
- **核心贡献**: H-NET++ introduces a hierarchical dynamic-chunking model for tokenizer-free language modeling in morphologically-rich languages, achieving state-of-the-art results through innovations like a lightweight Transformer context-mixer and curriculum-based training.

### [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](http://arxiv.org/abs/2508.05625v1)
- **类别**: `理论与分析` | **新颖性**: `4/5`
- **核心贡献**: 通过线性探针分析大型语言模型在多轮对话中的说服动态，揭示了说服成功、被说服者个性和说服策略等关键方面。

### [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](http://arxiv.org/abs/2508.05622v1)
- **类别**: `应用` | **新颖性**: `4/5`
- **核心贡献**: 引入基于大型语言模型的多智能体框架LearnerAgent，模拟真实教学环境，探索人类学习动态。

### [The Missing Reward: Active Inference in the Era of Experience](http://arxiv.org/abs/2508.05619v1)
- **类别**: `理论与分析` | **新颖性**: `4/5`
- **核心贡献**: 提出Active Inference（AIF）作为解决当代AI系统在自主制定、适应和追求目标方面的不足，即'grounded-agency gap'，的关键方法，通过将外部奖励信号替换为最小化自由能的内在驱动力，结合大型语言模型作为生成世界模型，为开发能够从经验中学习同时保持与人类价值观一致的自主AI代理提供了理论基础。

### [Learning to Reason for Factuality](http://arxiv.org/abs/2508.05618v1)
- **类别**: `训练与优化` | **新颖性**: `4/5`
- **核心贡献**: 提出了一种新颖的奖励函数，结合事实精确度、回答详细程度和答案相关性，通过在线强化学习提高了大型语言模型在长形式事实性任务中的表现。

### [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](http://arxiv.org/abs/2508.05616v1)
- **类别**: `应用` | **新颖性**: `4/5`
- **核心贡献**: TrajEvo introduces a framework that leverages LLMs and evolutionary algorithms to automatically design and refine trajectory prediction heuristics, outperforming existing methods in accuracy and generalizability.

### [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](http://arxiv.org/abs/2508.05615v1)
- **类别**: `训练与优化` | **新颖性**: `4/5`
- **核心贡献**: 提出了GUI-RC和GUI-RCPO，通过测试时间缩放和测试时间强化学习，无需额外训练即可提高GUI定位的准确性。

### [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](http://arxiv.org/abs/2508.05614v1)
- **类别**: `评测与基准` | **新颖性**: `4/5`
- **核心贡献**: OmniEAR introduces a comprehensive framework for evaluating embodied agent reasoning in language models, highlighting challenges in tool usage and multi-agent coordination.

### [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](http://arxiv.org/abs/2508.05613v1)
- **类别**: `训练与优化` | **新颖性**: `4/5`
- **核心贡献**: 提出了Cooper框架，通过联合优化策略模型和奖励模型，增强了强化学习在大型语言模型中的鲁棒性并减轻了奖励黑客的风险。

### [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](http://arxiv.org/abs/2508.05612v1)
- **类别**: `训练与优化` | **新颖性**: `4/5`
- **核心贡献**: 提出了Shuffle-R1框架，通过动态重组轨迹采样和批次组合来解决优势崩溃和推出沉默问题，提高了多模态大型语言模型的强化学习微调效率。

### [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](http://arxiv.org/abs/2508.05606v1)
- **类别**: `多模态` | **新颖性**: `4/5`
- **核心贡献**: 提出了Uni-CoT，一个统一的思维链框架，通过宏观和微观两级推理范式，实现了在多模态任务中的连贯和基础推理。

### [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](http://arxiv.org/abs/2508.05600v1)
- **类别**: `安全与伦理` | **新颖性**: `4/5`
- **核心贡献**: 证明了在线性回归和线性分类中，仅需一个毒样样本即可成功注入后门，且不影响良性学习任务性能的'一毒假设'。

### [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](http://arxiv.org/abs/2508.05592v1)
- **类别**: `数据与预训练` | **新颖性**: `4/5`
- **核心贡献**: MathSmith introduces a novel framework for synthesizing challenging mathematical problems from scratch using concept-explanation pairs from PlanetMath and reinforcement learning to optimize problem difficulty and quality, significantly advancing LLM reasoning capabilities.

### [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](http://arxiv.org/abs/2508.05591v1)
- **类别**: `模型架构` | **新颖性**: `4/5`
- **核心贡献**: Demonstrates that Kolmogorov-Arnold Networks (KANs) outperform traditional MLPs and achieve competitive accuracy with state-of-the-art models for IoT threat detection, while offering superior interpretability.

### [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](http://arxiv.org/abs/2508.05587v1)
- **类别**: `训练与优化` | **新颖性**: `4/5`
- **核心贡献**: 扩展了PyKEEN框架，集成了一套先进的负采样器，以生成更有意义的负样本，同时保持与现有PyKEEN工作流程和管道的兼容性。

### [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](http://arxiv.org/abs/2508.05581v1)
- **类别**: `应用` | **新颖性**: `4/5`
- **核心贡献**: 本研究展示了大型语言模型通过迭代学习生成可解释且准确的计算表型的能力，为高血压患者的临床决策支持提供了可扩展的解决方案。

